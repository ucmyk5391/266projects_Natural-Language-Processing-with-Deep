{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa210ebbc6104f8c913742e8002bcada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87cac03c1c59485fb460ec0c241ea357",
              "IPY_MODEL_2f577a1414f64277a5660554bd630655",
              "IPY_MODEL_f83aa7728156464e94cb7177dad25677"
            ],
            "layout": "IPY_MODEL_2cf0d7578c984ca5833c22e6837136b7"
          }
        },
        "87cac03c1c59485fb460ec0c241ea357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32a4b4cb25fa41d4a376660fb35f4b83",
            "placeholder": "​",
            "style": "IPY_MODEL_5f6a460fa7fa4ce9b5b4109e7d31e5d4",
            "value": "Map: 100%"
          }
        },
        "2f577a1414f64277a5660554bd630655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a1a3c70bd349d69f4dfe00f3739a2a",
            "max": 60000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f05b0781eb342fe96c48c41a0949f21",
            "value": 60000
          }
        },
        "f83aa7728156464e94cb7177dad25677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f79cba5cfa460b8deab3c2fdd0c8d6",
            "placeholder": "​",
            "style": "IPY_MODEL_257ccc437a99477f90d011dae4c86088",
            "value": " 60000/60000 [00:05&lt;00:00, 12172.88 examples/s]"
          }
        },
        "2cf0d7578c984ca5833c22e6837136b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a4b4cb25fa41d4a376660fb35f4b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6a460fa7fa4ce9b5b4109e7d31e5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6a1a3c70bd349d69f4dfe00f3739a2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f05b0781eb342fe96c48c41a0949f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6f79cba5cfa460b8deab3c2fdd0c8d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "257ccc437a99477f90d011dae4c86088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f293d8acc8494c39aff84bf0e6ef8fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb57d0bf9d2a40d5923574036d32876e",
              "IPY_MODEL_c99f33834e69451bb2d839eb2a2e73c4",
              "IPY_MODEL_b60763dfca3e4407a37eeda6dcd3e702"
            ],
            "layout": "IPY_MODEL_05357b876de2473a83c2c707d00bb377"
          }
        },
        "fb57d0bf9d2a40d5923574036d32876e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece3fdff499545058045cff690747734",
            "placeholder": "​",
            "style": "IPY_MODEL_bd152d07806d45f1b4170c337be0b0f9",
            "value": "Map: 100%"
          }
        },
        "c99f33834e69451bb2d839eb2a2e73c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4bee638dbf74636a529df2ec274536b",
            "max": 15000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_292f0259fa4b4e108ec12c555b14cbd6",
            "value": 15000
          }
        },
        "b60763dfca3e4407a37eeda6dcd3e702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_062762c2dd134ce999028ef2fbeefe97",
            "placeholder": "​",
            "style": "IPY_MODEL_2820bd7ddc584fd19d902e047f0d8211",
            "value": " 15000/15000 [00:01&lt;00:00, 12204.39 examples/s]"
          }
        },
        "05357b876de2473a83c2c707d00bb377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece3fdff499545058045cff690747734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd152d07806d45f1b4170c337be0b0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4bee638dbf74636a529df2ec274536b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292f0259fa4b4e108ec12c555b14cbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "062762c2dd134ce999028ef2fbeefe97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2820bd7ddc584fd19d902e047f0d8211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6cb2f74324e461890bccc0242a99b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b78534b18ac54813940e8a496b537318",
              "IPY_MODEL_ecd6dc14836e42f1bade15db393e85e2",
              "IPY_MODEL_9450a4bdce7b4002b1ecba5f948ca6a4"
            ],
            "layout": "IPY_MODEL_e89d1378ec53416eae209fbb55a29ff0"
          }
        },
        "b78534b18ac54813940e8a496b537318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baec9f9387d846cea07705e44f194051",
            "placeholder": "​",
            "style": "IPY_MODEL_11953c2f01664f7b8b585f0334a16c3f",
            "value": "Map: 100%"
          }
        },
        "ecd6dc14836e42f1bade15db393e85e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e25454973c8c46dbaa8d8ea7d897a866",
            "max": 15000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3048467653554c8c9f32b510c80a6076",
            "value": 15000
          }
        },
        "9450a4bdce7b4002b1ecba5f948ca6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8277d7bf3de0497585da3d0c87596e62",
            "placeholder": "​",
            "style": "IPY_MODEL_ef3666c034a5463e9e06a71205a41f3f",
            "value": " 15000/15000 [00:01&lt;00:00, 10364.60 examples/s]"
          }
        },
        "e89d1378ec53416eae209fbb55a29ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baec9f9387d846cea07705e44f194051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11953c2f01664f7b8b585f0334a16c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e25454973c8c46dbaa8d8ea7d897a866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3048467653554c8c9f32b510c80a6076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8277d7bf3de0497585da3d0c87596e62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef3666c034a5463e9e06a71205a41f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Install required packages\n",
        "!pip install -U transformers\n",
        "!pip install bert-score sentence-transformers rouge-score nltk\n",
        "!pip install -q -U evaluate\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "#Evaluation\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.corpus import cmudict\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score as bert_score\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import evaluate\n",
        "import random\n",
        "\n",
        "#Transformers\n",
        "from transformers import (\n",
        "    T5TokenizerFast,\n",
        "    T5ForConditionalGeneration,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification\n",
        ")\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "fpZm_KkDeCQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "287ced29-62ac-4823-8f74-f0c702180d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.54.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (25.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.34.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.7.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount drive folder and read data set files\n",
        "drive.mount('/content/drive')\n",
        "train_file = 'drive/MyDrive/Colab Notebooks/w266/Project/data/train_data.xlsx'\n",
        "test_file = 'drive/MyDrive/Colab Notebooks/w266/Project/data/test_data.xlsx'\n",
        "val_file = 'drive/MyDrive/Colab Notebooks/w266/Project/data/val_data.xlsx'\n",
        "df_train = pd.read_excel(train_file)\n",
        "df_test = pd.read_excel(test_file)\n",
        "df_val = pd.read_excel(val_file)\n",
        "\n",
        "#Trim dataset and create input_text and target_text\n",
        "df_train = df_train\n",
        "df_val = df_val\n",
        "df_test = df_test\n",
        "df_train['input_text'] = df_train['line1'].apply(lambda x: f\"Given this rap line, generate the next line: {x}\")\n",
        "df_train['target_text'] = df_train['line2']\n",
        "df_val['input_text'] = df_val['line1'].apply(lambda x: f\"Given this rap line, generate the next line: {x}\")\n",
        "df_val['target_text'] = df_val['line2']\n",
        "df_test['input_text'] = df_test['line1'].apply(lambda x: f\"Given this rap line, generate the next line: {x}\")\n",
        "df_test['target_text'] = df_test['line2']\n",
        "\n",
        "#Create datasets from dfs\n",
        "dataset = Dataset.from_pandas(df_train[['input_text', 'target_text']])\n",
        "val_dataset = Dataset.from_pandas(df_val[['input_text', 'target_text']])\n",
        "test_dataset = Dataset.from_pandas(df_test[['input_text', 'target_text']])\n",
        "\n",
        "#Load tokenizer and model\n",
        "model_name = 'google/flan-t5-base'\n",
        "tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "#Preprocess data with tokenizer and create tokenized datasets\n",
        "def preprocess(example):\n",
        "    model_input = tokenizer(example['input_text'], padding=\"max_length\", truncation=True, max_length=64)\n",
        "    labels = tokenizer(example['target_text'], padding=\"max_length\", truncation=True, max_length=64)\n",
        "    model_input['labels'] = labels['input_ids']\n",
        "    return model_input\n",
        "tokenized_dataset = dataset.map(preprocess, batched=True)\n",
        "tokenized_val_dataset = val_dataset.map(preprocess, batched=True)\n",
        "tokenized_test_dataset = test_dataset.map(preprocess, batched=True)\n"
      ],
      "metadata": {
        "id": "0SLMvRqi60gO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "aa210ebbc6104f8c913742e8002bcada",
            "87cac03c1c59485fb460ec0c241ea357",
            "2f577a1414f64277a5660554bd630655",
            "f83aa7728156464e94cb7177dad25677",
            "2cf0d7578c984ca5833c22e6837136b7",
            "32a4b4cb25fa41d4a376660fb35f4b83",
            "5f6a460fa7fa4ce9b5b4109e7d31e5d4",
            "e6a1a3c70bd349d69f4dfe00f3739a2a",
            "5f05b0781eb342fe96c48c41a0949f21",
            "b6f79cba5cfa460b8deab3c2fdd0c8d6",
            "257ccc437a99477f90d011dae4c86088",
            "f293d8acc8494c39aff84bf0e6ef8fe9",
            "fb57d0bf9d2a40d5923574036d32876e",
            "c99f33834e69451bb2d839eb2a2e73c4",
            "b60763dfca3e4407a37eeda6dcd3e702",
            "05357b876de2473a83c2c707d00bb377",
            "ece3fdff499545058045cff690747734",
            "bd152d07806d45f1b4170c337be0b0f9",
            "a4bee638dbf74636a529df2ec274536b",
            "292f0259fa4b4e108ec12c555b14cbd6",
            "062762c2dd134ce999028ef2fbeefe97",
            "2820bd7ddc584fd19d902e047f0d8211",
            "c6cb2f74324e461890bccc0242a99b55",
            "b78534b18ac54813940e8a496b537318",
            "ecd6dc14836e42f1bade15db393e85e2",
            "9450a4bdce7b4002b1ecba5f948ca6a4",
            "e89d1378ec53416eae209fbb55a29ff0",
            "baec9f9387d846cea07705e44f194051",
            "11953c2f01664f7b8b585f0334a16c3f",
            "e25454973c8c46dbaa8d8ea7d897a866",
            "3048467653554c8c9f32b510c80a6076",
            "8277d7bf3de0497585da3d0c87596e62",
            "ef3666c034a5463e9e06a71205a41f3f"
          ]
        },
        "outputId": "13e816de-b9f3-492f-a6e4-343278f6874f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/60000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa210ebbc6104f8c913742e8002bcada"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f293d8acc8494c39aff84bf0e6ef8fe9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6cb2f74324e461890bccc0242a99b55"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model & Tokenizer\n",
        "# trainer.save_model('drive/MyDrive/Colab Notebooks/w266/Project/models/flan-t5-base')\n",
        "# tokenizer.save_pretrained('drive/MyDrive/Colab Notebooks/w266/Project/models/flan-t5-baseline')"
      ],
      "metadata": {
        "id": "mGSoP3wTG1OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_path = 'drive/MyDrive/Colab Notebooks/w266/Project/models/flan-t5-baseline'\n",
        "# tokenizer = T5TokenizerFast.from_pretrained(model_path)\n",
        "# model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "# model = model.to(device)\n",
        "# model.eval()"
      ],
      "metadata": {
        "id": "G_JdeY57CGzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "#Add Prompts\n",
        "prompts = [f\"Given this rap line, generate the next line:  {row['line1']}\" for _, row in df_test.iterrows()]\n",
        "true_lines = [row['line2'] for _, row in df_test.iterrows()]\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "#Process in batches\n",
        "for i in range(0, len(prompts), batch_size):\n",
        "    prompt_batch = prompts[i:i+batch_size]\n",
        "    true_line_batch = true_lines[i:i+batch_size]\n",
        "\n",
        "    #Tokenize as batch\n",
        "    inputs = tokenizer(prompt_batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    #Generate all predictions\n",
        "    output_ids = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        max_new_tokens=30,\n",
        "        temperature=0.8,\n",
        "        do_sample=True,\n",
        "        num_beams=1\n",
        "    )\n",
        "\n",
        "    #Decode outputs\n",
        "    generated_lines = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "\n",
        "    #Store results\n",
        "    for prompt, true_line, gen_line in zip(prompt_batch, true_line_batch, generated_lines):\n",
        "        results.append({\n",
        "            \"prompt\": prompt,\n",
        "            \"actual_line2\": true_line,\n",
        "            \"generated_line2\": gen_line\n",
        "        })\n"
      ],
      "metadata": {
        "id": "zckiarrBBmkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of examples to print\n",
        "num_samples = 5\n",
        "\n",
        "#Randomly sample from results\n",
        "sampled = random.sample(results, k=min(num_samples, len(results)))\n",
        "\n",
        "#Print each example\n",
        "for i, r in enumerate(sampled, 1):\n",
        "    print(f\"--- Example {i} ---\")\n",
        "    print(f\"Prompt:         {r['prompt']}\")\n",
        "    print(f\"Actual Line 2:  {r['actual_line2']}\")\n",
        "    print(f\"Generated Line: {r['generated_line2']}\\n\")"
      ],
      "metadata": {
        "id": "FknlHRLwCLvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56735f10-b456-4745-d4c0-b0a2d1ad0f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Example 1 ---\n",
            "Prompt:         Given this rap line, generate the next line:  Now days you see me in the same shit\n",
            "Actual Line 2:  I didn't have the detergent\n",
            "Generated Line: oh i'm gonna live in the same room at the same time\n",
            "\n",
            "--- Example 2 ---\n",
            "Prompt:         Given this rap line, generate the next line:  Is that why you think I'm cool\n",
            "Actual Line 2:  Because I get fucked up, fucked up?\n",
            "Generated Line: you know, I was pretty cool\n",
            "\n",
            "--- Example 3 ---\n",
            "Prompt:         Given this rap line, generate the next line:  Strappin' in with the troops and my syndicate\n",
            "Actual Line 2:  Swear to God, get the fuck out my face, nigga (Yeah)\n",
            "Generated Line: he's a good guy\n",
            "\n",
            "--- Example 4 ---\n",
            "Prompt:         Given this rap line, generate the next line:  I hear your heart beatin, keep runnin your mouth, yeah\n",
            "Actual Line 2:  Your mouth runnin ahead of you, your mouth do what your legs should do\n",
            "Generated Line: i'm a little liar, ain't it cool in there, okay?\n",
            "\n",
            "--- Example 5 ---\n",
            "Prompt:         Given this rap line, generate the next line:  And the girl so cool she brought and extra homie\n",
            "Actual Line 2:  Girl on girl no question homie\n",
            "Generated Line: she brought her homie joggin\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "class ComprehensiveEvaluator:\n",
        "    def __init__(self):\n",
        "        # Initialize Sentence-BERT model\n",
        "        self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        # Initialize ROUGE scorer\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "        # Initialize CMU dictionary\n",
        "        self.cmu_dict = cmudict.dict()\n",
        "\n",
        "        # Initialize BLEU smoothing function\n",
        "        self.bleu_smoothing = SmoothingFunction().method1\n",
        "\n",
        "    def calculate_bleu_scores(self, test_results):\n",
        "        \"\"\"Calculate BLEU scores for all test results\"\"\"\n",
        "        bleu_scores = []\n",
        "\n",
        "        for result in test_results:\n",
        "            reference = [result['actual'].split()]\n",
        "            candidate = result['generated'].split()\n",
        "\n",
        "            if candidate:  # Only calculate if generation is not empty\n",
        "                score = sentence_bleu(reference, candidate, smoothing_function=self.bleu_smoothing)\n",
        "                bleu_scores.append(score)\n",
        "            else:\n",
        "                bleu_scores.append(0.0)\n",
        "\n",
        "        return {\n",
        "            'individual_scores': bleu_scores,\n",
        "            'average': np.mean(bleu_scores),\n",
        "            'std': np.std(bleu_scores),\n",
        "            'min': np.min(bleu_scores),\n",
        "            'max': np.max(bleu_scores)\n",
        "        }\n",
        "\n",
        "    def calculate_rouge_scores(self, test_results):\n",
        "        \"\"\"Calculate ROUGE scores for all test results\"\"\"\n",
        "        rouge1_scores = []\n",
        "        rouge2_scores = []\n",
        "        rougeL_scores = []\n",
        "\n",
        "        for result in test_results:\n",
        "            if result['generated'].strip():  # Only calculate if generation is not empty\n",
        "                scores = self.rouge_scorer.score(result['actual'], result['generated'])\n",
        "                rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "                rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "                rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "            else:\n",
        "                rouge1_scores.append(0.0)\n",
        "                rouge2_scores.append(0.0)\n",
        "                rougeL_scores.append(0.0)\n",
        "\n",
        "        return {\n",
        "            'rouge1': {\n",
        "                'individual_scores': rouge1_scores,\n",
        "                'average': np.mean(rouge1_scores),\n",
        "                'std': np.std(rouge1_scores)\n",
        "            },\n",
        "            'rouge2': {\n",
        "                'individual_scores': rouge2_scores,\n",
        "                'average': np.mean(rouge2_scores),\n",
        "                'std': np.std(rouge2_scores)\n",
        "            },\n",
        "            'rougeL': {\n",
        "                'individual_scores': rougeL_scores,\n",
        "                'average': np.mean(rougeL_scores),\n",
        "                'std': np.std(rougeL_scores)\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def calculate_bert_scores(self, test_results):\n",
        "        \"\"\"Calculate BERTScore for all test results\"\"\"\n",
        "        candidates = [result['generated'] for result in test_results]\n",
        "        references = [result['actual'] for result in test_results]\n",
        "\n",
        "        # Calculate BERTScore\n",
        "        P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=False)\n",
        "\n",
        "        return {\n",
        "            'precision': {\n",
        "                'average': P.mean().item(),\n",
        "                'std': P.std().item(),\n",
        "                'individual_scores': P.tolist()\n",
        "            },\n",
        "            'recall': {\n",
        "                'average': R.mean().item(),\n",
        "                'std': R.std().item(),\n",
        "                'individual_scores': R.tolist()\n",
        "            },\n",
        "            'f1': {\n",
        "                'average': F1.mean().item(),\n",
        "                'std': F1.std().item(),\n",
        "                'individual_scores': F1.tolist()\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def calculate_sentence_similarity(self, test_results):\n",
        "        \"\"\"Calculate sentence-level cosine similarity using Sentence-BERT\"\"\"\n",
        "        actual_lines = [result['actual'] for result in test_results]\n",
        "        generated_lines = [result['generated'] for result in test_results]\n",
        "\n",
        "        # Encode all sentences\n",
        "        actual_embeddings = self.sentence_model.encode(actual_lines, convert_to_tensor=True)\n",
        "        generated_embeddings = self.sentence_model.encode(generated_lines, convert_to_tensor=True)\n",
        "\n",
        "        # Calculate cosine similarity\n",
        "        cosine_scores = util.pytorch_cos_sim(actual_embeddings, generated_embeddings)\n",
        "\n",
        "        # Extract diagonal (pairwise similarities)\n",
        "        similarities = [cosine_scores[i][i].item() for i in range(len(actual_lines))]\n",
        "\n",
        "        return {\n",
        "            'individual_scores': similarities,\n",
        "            'average': np.mean(similarities),\n",
        "            'std': np.std(similarities),\n",
        "            'min': np.min(similarities),\n",
        "            'max': np.max(similarities)\n",
        "        }\n",
        "\n",
        "    def get_last_word(self, line):\n",
        "        \"\"\"Extract the last word from a line for rhyme analysis\"\"\"\n",
        "        words = line.lower().strip().split()\n",
        "        if words:\n",
        "            # Remove punctuation from last word\n",
        "            last_word = ''.join(c for c in words[-1] if c.isalpha())\n",
        "            return last_word\n",
        "        return \"\"\n",
        "\n",
        "    def get_rhyme_part_cmu(self, word):\n",
        "        \"\"\"Extract the rhyming part using CMU dictionary\"\"\"\n",
        "        if word in self.cmu_dict:\n",
        "            pronunciations = self.cmu_dict[word]\n",
        "            if pronunciations:\n",
        "                # Get the part after the last stressed vowel\n",
        "                pron = pronunciations[0]\n",
        "                for i in range(len(pron) - 1, -1, -1):\n",
        "                    if pron[i][-1].isdigit():  # Stressed vowel\n",
        "                        return pron[i:]\n",
        "        return None\n",
        "\n",
        "    def analyze_rhymes_cmu(self, test_results):\n",
        "        \"\"\"Analyze rhymes using CMU dictionary\"\"\"\n",
        "        phonetic_rhymes = 0\n",
        "        total_valid = 0\n",
        "\n",
        "        rhyme_details = []\n",
        "\n",
        "        for i, result in enumerate(test_results):\n",
        "            input_last = self.get_last_word(result['input'])\n",
        "            generated_last = self.get_last_word(result['generated'])\n",
        "\n",
        "            if input_last and generated_last:\n",
        "                input_rhyme = self.get_rhyme_part_cmu(input_last)\n",
        "                generated_rhyme = self.get_rhyme_part_cmu(generated_last)\n",
        "\n",
        "                if input_rhyme and generated_rhyme:\n",
        "                    total_valid += 1\n",
        "\n",
        "                    is_rhyme = input_rhyme == generated_rhyme\n",
        "                    if is_rhyme:\n",
        "                        phonetic_rhymes += 1\n",
        "\n",
        "                    rhyme_details.append({\n",
        "                        'example_index': i,\n",
        "                        'input_word': input_last,\n",
        "                        'generated_word': generated_last,\n",
        "                        'input_phonemes': input_rhyme,\n",
        "                        'generated_phonemes': generated_rhyme,\n",
        "                        'is_rhyme': is_rhyme\n",
        "                    })\n",
        "\n",
        "        return {\n",
        "            'phonetic_rhyme_rate': phonetic_rhymes / total_valid if total_valid > 0 else 0,\n",
        "            'phonetic_rhymes': phonetic_rhymes,\n",
        "            'total_valid': total_valid,\n",
        "            'details': rhyme_details\n",
        "        }\n",
        "\n",
        "    def calculate_length_similarity(self, test_results):\n",
        "        \"\"\"Calculate length similarity between actual and generated lines\"\"\"\n",
        "        length_diffs = []\n",
        "        length_ratios = []\n",
        "\n",
        "        for result in test_results:\n",
        "            actual_len = len(result['actual'].split())\n",
        "            generated_len = len(result['generated'].split())\n",
        "\n",
        "            length_diffs.append(abs(actual_len - generated_len))\n",
        "\n",
        "            if actual_len > 0:\n",
        "                length_ratios.append(generated_len / actual_len)\n",
        "            else:\n",
        "                length_ratios.append(0.0)\n",
        "\n",
        "        return {\n",
        "            'average_length_diff': np.mean(length_diffs),\n",
        "            'std_length_diff': np.std(length_diffs),\n",
        "            'average_length_ratio': np.mean(length_ratios),\n",
        "            'std_length_ratio': np.std(length_ratios)\n",
        "        }\n",
        "\n",
        "    def evaluate_comprehensive(self, test_results):\n",
        "        \"\"\"Run comprehensive evaluation on test results\"\"\"\n",
        "        print(\"=\" * 80)\n",
        "        print(\"COMPREHENSIVE EVALUATION RESULTS\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # Basic statistics\n",
        "        total_examples = len(test_results)\n",
        "        empty_generations = sum(1 for r in test_results if not r['generated'].strip())\n",
        "\n",
        "        print(f\"Dataset Statistics:\")\n",
        "        print(f\"  Total Examples: {total_examples}\")\n",
        "        print(f\"  Empty Generations: {empty_generations} ({empty_generations/total_examples:.1%})\")\n",
        "        print()\n",
        "\n",
        "        # Calculate all metrics\n",
        "        print(\"Computing metrics...\")\n",
        "\n",
        "        # Traditional NLP metrics\n",
        "        bleu_results = self.calculate_bleu_scores(test_results)\n",
        "        rouge_results = self.calculate_rouge_scores(test_results)\n",
        "        bert_results = self.calculate_bert_scores(test_results)\n",
        "\n",
        "        # Sentence-level similarity\n",
        "        sentence_sim_results = self.calculate_sentence_similarity(test_results)\n",
        "\n",
        "        # Rhyme analysis\n",
        "        # dandelion_rhyme_results = self.analyze_rhymes_dandelion(test_results)\n",
        "        cmu_rhyme_results = self.analyze_rhymes_cmu(test_results)\n",
        "\n",
        "        # Length analysis\n",
        "        length_results = self.calculate_length_similarity(test_results)\n",
        "\n",
        "        # Display results\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"TRADITIONAL NLP METRICS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"BLEU Score:\")\n",
        "        print(f\"  Average: {bleu_results['average']:.4f} (±{bleu_results['std']:.4f})\")\n",
        "        print(f\"  Range: {bleu_results['min']:.4f} - {bleu_results['max']:.4f}\")\n",
        "\n",
        "        print(f\"\\nROUGE Scores:\")\n",
        "        print(f\"  ROUGE-1: {rouge_results['rouge1']['average']:.4f} (±{rouge_results['rouge1']['std']:.4f})\")\n",
        "        print(f\"  ROUGE-2: {rouge_results['rouge2']['average']:.4f} (±{rouge_results['rouge2']['std']:.4f})\")\n",
        "        print(f\"  ROUGE-L: {rouge_results['rougeL']['average']:.4f} (±{rouge_results['rougeL']['std']:.4f})\")\n",
        "\n",
        "        print(f\"\\nBERTScore:\")\n",
        "        print(f\"  F1: {bert_results['f1']['average']:.4f} (±{bert_results['f1']['std']:.4f})\")\n",
        "        print(f\"  Precision: {bert_results['precision']['average']:.4f} (±{bert_results['precision']['std']:.4f})\")\n",
        "        print(f\"  Recall: {bert_results['recall']['average']:.4f} (±{bert_results['recall']['std']:.4f})\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"SENTENCE-LEVEL SEMANTIC SIMILARITY\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"Sentence-BERT Cosine Similarity:\")\n",
        "        print(f\"  Average: {sentence_sim_results['average']:.4f} (±{sentence_sim_results['std']:.4f})\")\n",
        "        print(f\"  Range: {sentence_sim_results['min']:.4f} - {sentence_sim_results['max']:.4f}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"RHYME ANALYSIS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"\\nCMU Dictionary Phonetic Analysis:\")\n",
        "        print(f\"  Phonetic Rhyme Rate: {cmu_rhyme_results['phonetic_rhyme_rate']:.2%}\")\n",
        "        print(f\"  Valid Examples: {cmu_rhyme_results['total_valid']}/{total_examples}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"LENGTH ANALYSIS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"Length Similarity:\")\n",
        "        print(f\"  Average Length Difference: {length_results['average_length_diff']:.2f} words\")\n",
        "        print(f\"  Average Length Ratio: {length_results['average_length_ratio']:.2f}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # Return all results for further analysis\n",
        "        return {\n",
        "            'basic_stats': {\n",
        "                'total_examples': total_examples,\n",
        "                'empty_generations': empty_generations\n",
        "            },\n",
        "            'bleu': bleu_results,\n",
        "            'rouge': rouge_results,\n",
        "            'bert_score': bert_results,\n",
        "            'sentence_similarity': sentence_sim_results,\n",
        "            # 'dandelion_rhyme': dandelion_rhyme_results,\n",
        "            'cmu_rhyme': cmu_rhyme_results,\n",
        "            'length_analysis': length_results\n",
        "        }\n"
      ],
      "metadata": {
        "id": "j612jfRyD9dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3565742f-5466-4e33-faaa-f37142f5df94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = []\n",
        "\n",
        "for r in results:\n",
        "    test_results.append({\n",
        "        \"input\": r[\"prompt\"],\n",
        "        \"actual\": r[\"actual_line2\"],\n",
        "        \"generated\": r[\"generated_line2\"]\n",
        "    })"
      ],
      "metadata": {
        "id": "kMGRofbSEjiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.corpus import cmudict\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score as bert_score\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from typing import Dict, List, Any\n",
        "import warnings\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('cmudict', quiet=True)\n",
        "\n",
        "class ComprehensiveEvaluator:\n",
        "    def __init__(self, sentence_model_name: str = 'all-MiniLM-L6-v2', device: str = None):\n",
        "        \"\"\"\n",
        "        Initialize evaluator with configurable models and device\n",
        "\n",
        "        Args:\n",
        "            sentence_model_name: Name of sentence transformer model to use\n",
        "            device: Device to run models on ('cuda', 'cpu', or None for auto)\n",
        "        \"\"\"\n",
        "        # Set device\n",
        "        if device is None:\n",
        "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        print(f\"Initializing evaluator on device: {self.device}\")\n",
        "\n",
        "        # Initialize models with error handling\n",
        "        try:\n",
        "            self.sentence_model = SentenceTransformer(sentence_model_name, device=self.device)\n",
        "            print(f\"✓ Loaded Sentence-BERT model: {sentence_model_name}\")\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Failed to load Sentence-BERT model: {e}\")\n",
        "            self.sentence_model = None\n",
        "\n",
        "        # Initialize ROUGE scorer\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "        # Initialize CMU dictionary with error handling\n",
        "        try:\n",
        "            self.cmu_dict = cmudict.dict()\n",
        "            print(f\"✓ Loaded CMU dictionary with {len(self.cmu_dict)} entries\")\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Failed to load CMU dictionary: {e}\")\n",
        "            self.cmu_dict = {}\n",
        "\n",
        "        # Initialize BLEU smoothing function\n",
        "        self.bleu_smoothing = SmoothingFunction().method1\n",
        "\n",
        "        # Cache for performance\n",
        "        self._rhyme_cache = {}\n",
        "\n",
        "    def calculate_bleu_scores(self, test_results: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Calculate BLEU scores with improved handling\"\"\"\n",
        "        bleu_scores = []\n",
        "        valid_count = 0\n",
        "        empty_count = 0\n",
        "\n",
        "        for result in test_results:\n",
        "            actual = result['actual'].strip()\n",
        "            generated = result['generated'].strip()\n",
        "\n",
        "            if not generated:\n",
        "                empty_count += 1\n",
        "                bleu_scores.append(0.0)\n",
        "            elif not actual:\n",
        "                empty_count += 1\n",
        "                bleu_scores.append(0.0)\n",
        "            else:\n",
        "                valid_count += 1\n",
        "                reference = [actual.split()]\n",
        "                candidate = generated.split()\n",
        "\n",
        "                score = sentence_bleu(reference, candidate, smoothing_function=self.bleu_smoothing)\n",
        "                bleu_scores.append(score)\n",
        "\n",
        "        return {\n",
        "            'individual_scores': bleu_scores,\n",
        "            'average': np.mean(bleu_scores),\n",
        "            'std': np.std(bleu_scores),\n",
        "            'min': np.min(bleu_scores),\n",
        "            'max': np.max(bleu_scores),\n",
        "            'valid_count': valid_count,\n",
        "            'empty_count': empty_count\n",
        "        }\n",
        "\n",
        "    def calculate_rouge_scores(self, test_results: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Calculate ROUGE scores with enhanced tracking\"\"\"\n",
        "        rouge1_scores = []\n",
        "        rouge2_scores = []\n",
        "        rougeL_scores = []\n",
        "\n",
        "        valid_count = 0\n",
        "        empty_count = 0\n",
        "\n",
        "        for result in test_results:\n",
        "            actual = result['actual'].strip()\n",
        "            generated = result['generated'].strip()\n",
        "\n",
        "            if not generated or not actual:\n",
        "                empty_count += 1\n",
        "                rouge1_scores.append(0.0)\n",
        "                rouge2_scores.append(0.0)\n",
        "                rougeL_scores.append(0.0)\n",
        "            else:\n",
        "                valid_count += 1\n",
        "                scores = self.rouge_scorer.score(actual, generated)\n",
        "                rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "                rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "                rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "        return {\n",
        "            'rouge1': {\n",
        "                'individual_scores': rouge1_scores,\n",
        "                'average': np.mean(rouge1_scores),\n",
        "                'std': np.std(rouge1_scores),\n",
        "                'valid_count': valid_count,\n",
        "                'empty_count': empty_count\n",
        "            },\n",
        "            'rouge2': {\n",
        "                'individual_scores': rouge2_scores,\n",
        "                'average': np.mean(rouge2_scores),\n",
        "                'std': np.std(rouge2_scores),\n",
        "                'valid_count': valid_count,\n",
        "                'empty_count': empty_count\n",
        "            },\n",
        "            'rougeL': {\n",
        "                'individual_scores': rougeL_scores,\n",
        "                'average': np.mean(rougeL_scores),\n",
        "                'std': np.std(rougeL_scores),\n",
        "                'valid_count': valid_count,\n",
        "                'empty_count': empty_count\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def calculate_bert_scores(self, test_results: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Calculate BERTScore with batch processing\"\"\"\n",
        "        candidates = [result['generated'] for result in test_results]\n",
        "        references = [result['actual'] for result in test_results]\n",
        "\n",
        "        try:\n",
        "            # Calculate BERTScore with device specification\n",
        "            P, R, F1 = bert_score(candidates, references, lang=\"en\", verbose=False, device=self.device)\n",
        "\n",
        "            return {\n",
        "                'precision': {\n",
        "                    'average': P.mean().item(),\n",
        "                    'std': P.std().item(),\n",
        "                    'individual_scores': P.tolist()\n",
        "                },\n",
        "                'recall': {\n",
        "                    'average': R.mean().item(),\n",
        "                    'std': R.std().item(),\n",
        "                    'individual_scores': R.tolist()\n",
        "                },\n",
        "                'f1': {\n",
        "                    'average': F1.mean().item(),\n",
        "                    'std': F1.std().item(),\n",
        "                    'individual_scores': F1.tolist()\n",
        "                }\n",
        "            }\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"BERTScore calculation failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def calculate_sentence_similarity(self, test_results: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Calculate sentence similarity with error handling\"\"\"\n",
        "        if self.sentence_model is None:\n",
        "            warnings.warn(\"Sentence-BERT model not available\")\n",
        "            return None\n",
        "\n",
        "        actual_lines = [result['actual'] for result in test_results]\n",
        "        generated_lines = [result['generated'] for result in test_results]\n",
        "\n",
        "        try:\n",
        "            # Encode all sentences with batch processing\n",
        "            actual_embeddings = self.sentence_model.encode(actual_lines, convert_to_tensor=True, show_progress_bar=False)\n",
        "            generated_embeddings = self.sentence_model.encode(generated_lines, convert_to_tensor=True, show_progress_bar=False)\n",
        "\n",
        "            # Calculate cosine similarity\n",
        "            cosine_scores = util.pytorch_cos_sim(actual_embeddings, generated_embeddings)\n",
        "\n",
        "            # Extract diagonal (pairwise similarities)\n",
        "            similarities = [cosine_scores[i][i].item() for i in range(len(actual_lines))]\n",
        "\n",
        "            return {\n",
        "                'individual_scores': similarities,\n",
        "                'average': np.mean(similarities),\n",
        "                'std': np.std(similarities),\n",
        "                'min': np.min(similarities),\n",
        "                'max': np.max(similarities)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            warnings.warn(f\"Sentence similarity calculation failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_last_word(self, line: str) -> str:\n",
        "        \"\"\"Extract last word with improved cleaning\"\"\"\n",
        "        import re\n",
        "        # Use regex to better handle punctuation and contractions\n",
        "        words = re.findall(r\"\\b[a-zA-Z]+(?:'[a-zA-Z]+)?\\b\", line.lower())\n",
        "        return words[-1] if words else \"\"\n",
        "\n",
        "    def get_rhyme_part_cmu(self, word: str) -> List[str]:\n",
        "        \"\"\"Extract rhyming part with caching\"\"\"\n",
        "        if word in self._rhyme_cache:\n",
        "            return self._rhyme_cache[word]\n",
        "\n",
        "        if word in self.cmu_dict:\n",
        "            pronunciations = self.cmu_dict[word]\n",
        "            if pronunciations:\n",
        "                # Get the part after the last stressed vowel\n",
        "                pron = pronunciations[0]\n",
        "                for i in range(len(pron) - 1, -1, -1):\n",
        "                    if pron[i][-1].isdigit():  # Stressed vowel\n",
        "                        result = pron[i:]\n",
        "                        self._rhyme_cache[word] = result\n",
        "                        return result\n",
        "\n",
        "        self._rhyme_cache[word] = None\n",
        "        return None\n",
        "\n",
        "    def analyze_rhymes_cmu(self, test_results: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Enhanced rhyme analysis with better statistics\"\"\"\n",
        "        phonetic_rhymes = 0\n",
        "        near_rhymes = 0  # Rhymes with similar endings\n",
        "        total_valid = 0\n",
        "        total_processed = 0\n",
        "\n",
        "        rhyme_details = []\n",
        "\n",
        "        for i, result in enumerate(test_results):\n",
        "            input_last = self.get_last_word(result['input'])\n",
        "            generated_last = self.get_last_word(result['generated'])\n",
        "\n",
        "            total_processed += 1\n",
        "\n",
        "            if input_last and generated_last:\n",
        "                input_rhyme = self.get_rhyme_part_cmu(input_last)\n",
        "                generated_rhyme = self.get_rhyme_part_cmu(generated_last)\n",
        "\n",
        "                if input_rhyme and generated_rhyme:\n",
        "                    total_valid += 1\n",
        "\n",
        "                    is_perfect_rhyme = input_rhyme == generated_rhyme\n",
        "                    is_near_rhyme = False\n",
        "\n",
        "                    # Check for near rhymes (last 2 phonemes match)\n",
        "                    if not is_perfect_rhyme and len(input_rhyme) >= 2 and len(generated_rhyme) >= 2:\n",
        "                        is_near_rhyme = input_rhyme[-2:] == generated_rhyme[-2:]\n",
        "\n",
        "                    if is_perfect_rhyme:\n",
        "                        phonetic_rhymes += 1\n",
        "                    elif is_near_rhyme:\n",
        "                        near_rhymes += 1\n",
        "\n",
        "                    rhyme_details.append({\n",
        "                        'example_index': i,\n",
        "                        'input_word': input_last,\n",
        "                        'generated_word': generated_last,\n",
        "                        'input_phonemes': input_rhyme,\n",
        "                        'generated_phonemes': generated_rhyme,\n",
        "                        'is_perfect_rhyme': is_perfect_rhyme,\n",
        "                        'is_near_rhyme': is_near_rhyme\n",
        "                    })\n",
        "\n",
        "        return {\n",
        "            'perfect_rhyme_rate': phonetic_rhymes / total_valid if total_valid > 0 else 0,\n",
        "            'near_rhyme_rate': near_rhymes / total_valid if total_valid > 0 else 0,\n",
        "            'total_rhyme_rate': (phonetic_rhymes + near_rhymes) / total_valid if total_valid > 0 else 0,\n",
        "            'perfect_rhymes': phonetic_rhymes,\n",
        "            'near_rhymes': near_rhymes,\n",
        "            'total_valid': total_valid,\n",
        "            'total_processed': total_processed,\n",
        "            'coverage': total_valid / total_processed if total_processed > 0 else 0,\n",
        "            'details': rhyme_details\n",
        "        }\n",
        "\n",
        "    def calculate_additional_metrics(self, test_results: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Calculate additional rap-specific metrics\"\"\"\n",
        "\n",
        "        # Syllable analysis (approximate)\n",
        "        def count_syllables(word):\n",
        "            # Simple syllable counting heuristic\n",
        "            word = word.lower()\n",
        "            count = 0\n",
        "            vowels = \"aeiouy\"\n",
        "            if word[0] in vowels:\n",
        "                count += 1\n",
        "            for i in range(1, len(word)):\n",
        "                if word[i] in vowels and word[i-1] not in vowels:\n",
        "                    count += 1\n",
        "            if word.endswith(\"e\"):\n",
        "                count -= 1\n",
        "            if count == 0:\n",
        "                count += 1\n",
        "            return count\n",
        "\n",
        "        syllable_diffs = []\n",
        "        word_diversity_scores = []\n",
        "\n",
        "        for result in test_results:\n",
        "            actual_words = result['actual'].split()\n",
        "            generated_words = result['generated'].split()\n",
        "\n",
        "            # Syllable analysis\n",
        "            if actual_words and generated_words:\n",
        "                actual_syllables = sum(count_syllables(word) for word in actual_words)\n",
        "                generated_syllables = sum(count_syllables(word) for word in generated_words)\n",
        "                syllable_diffs.append(abs(actual_syllables - generated_syllables))\n",
        "            else:\n",
        "                syllable_diffs.append(0)\n",
        "\n",
        "            # Word diversity (unique words / total words)\n",
        "            if generated_words:\n",
        "                diversity = len(set(generated_words)) / len(generated_words)\n",
        "                word_diversity_scores.append(diversity)\n",
        "            else:\n",
        "                word_diversity_scores.append(0.0)\n",
        "\n",
        "        return {\n",
        "            'syllable_similarity': {\n",
        "                'average_diff': np.mean(syllable_diffs),\n",
        "                'std_diff': np.std(syllable_diffs)\n",
        "            },\n",
        "            'word_diversity': {\n",
        "                'average': np.mean(word_diversity_scores),\n",
        "                'std': np.std(word_diversity_scores)\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def evaluate_comprehensive(self, test_results: List[Dict], show_progress: bool = True) -> Dict[str, Any]:\n",
        "        \"\"\"Enhanced comprehensive evaluation with timing and progress\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "        print(\"COMPREHENSIVE EVALUATION RESULTS\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # Basic statistics\n",
        "        total_examples = len(test_results)\n",
        "        empty_generations = sum(1 for r in test_results if not r['generated'].strip())\n",
        "\n",
        "        print(f\"Dataset Statistics:\")\n",
        "        print(f\"  Total Examples: {total_examples}\")\n",
        "        print(f\"  Empty Generations: {empty_generations} ({empty_generations/total_examples:.1%})\")\n",
        "        print()\n",
        "\n",
        "        # Calculate all metrics with timing\n",
        "        results = {}\n",
        "\n",
        "        if show_progress:\n",
        "            print(\"Computing metrics...\")\n",
        "\n",
        "        # Traditional NLP metrics\n",
        "        if show_progress: print(\"  • BLEU scores...\")\n",
        "        results['bleu'] = self.calculate_bleu_scores(test_results)\n",
        "\n",
        "        if show_progress: print(\"  • ROUGE scores...\")\n",
        "        results['rouge'] = self.calculate_rouge_scores(test_results)\n",
        "\n",
        "        if show_progress: print(\"  • BERTScore...\")\n",
        "        results['bert_score'] = self.calculate_bert_scores(test_results)\n",
        "\n",
        "        # Sentence-level similarity\n",
        "        if show_progress: print(\"  • Sentence similarity...\")\n",
        "        results['sentence_similarity'] = self.calculate_sentence_similarity(test_results)\n",
        "\n",
        "        # Rhyme analysis\n",
        "        if show_progress: print(\"  • Rhyme analysis...\")\n",
        "        results['cmu_rhyme'] = self.analyze_rhymes_cmu(test_results)\n",
        "\n",
        "        # Additional metrics\n",
        "        if show_progress: print(\"  • Additional metrics...\")\n",
        "        results['additional_metrics'] = self.calculate_additional_metrics(test_results)\n",
        "\n",
        "        # Length analysis\n",
        "        results['length_analysis'] = self.calculate_length_similarity(test_results)\n",
        "\n",
        "        # Display results with enhanced formatting\n",
        "        self._display_results(results, total_examples, empty_generations)\n",
        "\n",
        "        execution_time = time.time() - start_time\n",
        "        print(f\"\\nEvaluation completed in {execution_time:.2f} seconds\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        # Add metadata\n",
        "        results['metadata'] = {\n",
        "            'total_examples': total_examples,\n",
        "            'empty_generations': empty_generations,\n",
        "            'execution_time': execution_time,\n",
        "            'device_used': self.device\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _display_results(self, results: Dict, total_examples: int, empty_generations: int):\n",
        "        \"\"\"Enhanced result display with better formatting\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"TRADITIONAL NLP METRICS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # BLEU\n",
        "        bleu = results['bleu']\n",
        "        print(f\"BLEU Score:\")\n",
        "        print(f\"  Average: {bleu['average']:.4f} (±{bleu['std']:.4f})\")\n",
        "        print(f\"  Range: {bleu['min']:.4f} - {bleu['max']:.4f}\")\n",
        "        print(f\"  Valid/Empty: {bleu['valid_count']}/{bleu['empty_count']}\")\n",
        "\n",
        "        # ROUGE\n",
        "        rouge = results['rouge']\n",
        "        print(f\"\\nROUGE Scores:\")\n",
        "        print(f\"  ROUGE-1: {rouge['rouge1']['average']:.4f} (±{rouge['rouge1']['std']:.4f})\")\n",
        "        print(f\"  ROUGE-2: {rouge['rouge2']['average']:.4f} (±{rouge['rouge2']['std']:.4f})\")\n",
        "        print(f\"  ROUGE-L: {rouge['rougeL']['average']:.4f} (±{rouge['rougeL']['std']:.4f})\")\n",
        "        print(f\"  Valid/Empty: {rouge['rouge1']['valid_count']}/{rouge['rouge1']['empty_count']}\")\n",
        "\n",
        "        # BERTScore\n",
        "        if results['bert_score']:\n",
        "            bert = results['bert_score']\n",
        "            print(f\"\\nBERTScore:\")\n",
        "            print(f\"  F1: {bert['f1']['average']:.4f} (±{bert['f1']['std']:.4f})\")\n",
        "            print(f\"  Precision: {bert['precision']['average']:.4f} (±{bert['precision']['std']:.4f})\")\n",
        "            print(f\"  Recall: {bert['recall']['average']:.4f} (±{bert['recall']['std']:.4f})\")\n",
        "\n",
        "        # Sentence similarity\n",
        "        if results['sentence_similarity']:\n",
        "            sent_sim = results['sentence_similarity']\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"SENTENCE-LEVEL SEMANTIC SIMILARITY\")\n",
        "            print(\"=\"*60)\n",
        "            print(f\"Sentence-BERT Cosine Similarity:\")\n",
        "            print(f\"  Average: {sent_sim['average']:.4f} (±{sent_sim['std']:.4f})\")\n",
        "            print(f\"  Range: {sent_sim['min']:.4f} - {sent_sim['max']:.4f}\")\n",
        "\n",
        "        # Rhyme analysis\n",
        "        rhyme = results['cmu_rhyme']\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"RHYME ANALYSIS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"CMU Dictionary Phonetic Analysis:\")\n",
        "        print(f\"  Perfect Rhyme Rate: {rhyme['perfect_rhyme_rate']:.2%}\")\n",
        "        print(f\"  Near Rhyme Rate: {rhyme['near_rhyme_rate']:.2%}\")\n",
        "        print(f\"  Total Rhyme Rate: {rhyme['total_rhyme_rate']:.2%}\")\n",
        "        print(f\"  Dictionary Coverage: {rhyme['coverage']:.1%} ({rhyme['total_valid']}/{rhyme['total_processed']})\")\n",
        "\n",
        "        # Additional metrics\n",
        "        additional = results['additional_metrics']\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"RAP-SPECIFIC METRICS\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Syllable Similarity:\")\n",
        "        print(f\"  Average Difference: {additional['syllable_similarity']['average_diff']:.2f} syllables\")\n",
        "        print(f\"Word Diversity:\")\n",
        "        print(f\"  Average: {additional['word_diversity']['average']:.3f}\")\n",
        "\n",
        "        # Length analysis\n",
        "        length = results['length_analysis']\n",
        "        print(f\"\\nLength Analysis:\")\n",
        "        print(f\"  Average Length Difference: {length['average_length_diff']:.2f} words\")\n",
        "        print(f\"  Average Length Ratio: {length['average_length_ratio']:.2f}\")\n",
        "\n",
        "    def calculate_length_similarity(self, test_results: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Enhanced length analysis\"\"\"\n",
        "        length_diffs = []\n",
        "        length_ratios = []\n",
        "\n",
        "        for result in test_results:\n",
        "            actual_len = len(result['actual'].split())\n",
        "            generated_len = len(result['generated'].split())\n",
        "\n",
        "            length_diffs.append(abs(actual_len - generated_len))\n",
        "\n",
        "            if actual_len > 0:\n",
        "                length_ratios.append(generated_len / actual_len)\n",
        "            else:\n",
        "                length_ratios.append(0.0)\n",
        "\n",
        "        return {\n",
        "            'average_length_diff': np.mean(length_diffs),\n",
        "            'std_length_diff': np.std(length_diffs),\n",
        "            'average_length_ratio': np.mean(length_ratios),\n",
        "            'std_length_ratio': np.std(length_ratios),\n",
        "            'individual_diffs': length_diffs,\n",
        "            'individual_ratios': length_ratios\n",
        "        }"
      ],
      "metadata": {
        "id": "O3NBr7SWjCub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize with custom settings\n",
        "evaluator = ComprehensiveEvaluator(\n",
        "    sentence_model_name='all-MiniLM-L6-v2',  # or 'all-mpnet-base-v2' for better quality\n",
        "    device='cuda'  # or 'cpu'\n",
        ")\n",
        "\n",
        "# Run evaluation\n",
        "comprehensive_results = evaluator.evaluate_comprehensive(test_results, show_progress=True)"
      ],
      "metadata": {
        "id": "J9FViTLnEmd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e29dfd3-ae57-4352-9e42-a3907750ac10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing evaluator on device: cuda\n",
            "✓ Loaded Sentence-BERT model: all-MiniLM-L6-v2\n",
            "✓ Loaded CMU dictionary with 123455 entries\n",
            "================================================================================\n",
            "COMPREHENSIVE EVALUATION RESULTS\n",
            "================================================================================\n",
            "Dataset Statistics:\n",
            "  Total Examples: 15000\n",
            "  Empty Generations: 78 (0.5%)\n",
            "\n",
            "Computing metrics...\n",
            "  • BLEU scores...\n",
            "  • ROUGE scores...\n",
            "  • BERTScore...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  • Sentence similarity...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  • Rhyme analysis...\n",
            "  • Additional metrics...\n",
            "\n",
            "============================================================\n",
            "TRADITIONAL NLP METRICS\n",
            "============================================================\n",
            "BLEU Score:\n",
            "  Average: 0.0177 (±0.0730)\n",
            "  Range: 0.0000 - 1.0000\n",
            "  Valid/Empty: 14922/78\n",
            "\n",
            "ROUGE Scores:\n",
            "  ROUGE-1: 0.1006 (±0.1626)\n",
            "  ROUGE-2: 0.0320 (±0.1269)\n",
            "  ROUGE-L: 0.0963 (±0.1587)\n",
            "  Valid/Empty: 14922/78\n",
            "\n",
            "BERTScore:\n",
            "  F1: 0.8282 (±0.0675)\n",
            "  Precision: 0.8347 (±0.0708)\n",
            "  Recall: 0.8225 (±0.0679)\n",
            "\n",
            "============================================================\n",
            "SENTENCE-LEVEL SEMANTIC SIMILARITY\n",
            "============================================================\n",
            "Sentence-BERT Cosine Similarity:\n",
            "  Average: 0.2053 (±0.1612)\n",
            "  Range: -0.0999 - 1.0000\n",
            "\n",
            "============================================================\n",
            "RHYME ANALYSIS\n",
            "============================================================\n",
            "CMU Dictionary Phonetic Analysis:\n",
            "  Perfect Rhyme Rate: 43.76%\n",
            "  Near Rhyme Rate: 0.04%\n",
            "  Total Rhyme Rate: 43.80%\n",
            "  Dictionary Coverage: 85.0% (12754/15000)\n",
            "\n",
            "============================================================\n",
            "RAP-SPECIFIC METRICS\n",
            "============================================================\n",
            "Syllable Similarity:\n",
            "  Average Difference: 4.95 syllables\n",
            "Word Diversity:\n",
            "  Average: 0.951\n",
            "\n",
            "Length Analysis:\n",
            "  Average Length Difference: 4.06 words\n",
            "  Average Length Ratio: 0.92\n",
            "\n",
            "Evaluation completed in 45.41 seconds\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}
